{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1067156,"sourceType":"datasetVersion","datasetId":592212}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing Necessary Libraries\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.layers import TextVectorization\nimport tensorflow_text as tf_text\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:45:25.091841Z","iopub.execute_input":"2024-03-01T02:45:25.092280Z","iopub.status.idle":"2024-03-01T02:45:45.657750Z","shell.execute_reply.started":"2024-03-01T02:45:25.092246Z","shell.execute_reply":"2024-03-01T02:45:45.656258Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-01 02:45:29.373947: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-01 02:45:29.374114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-01 02:45:29.585680: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Reading the data\ndata=pd.read_csv(\"/kaggle/input/language-translation-englishfrench/eng_-french.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:45:49.561915Z","iopub.execute_input":"2024-03-01T02:45:49.562665Z","iopub.status.idle":"2024-03-01T02:45:50.159498Z","shell.execute_reply.started":"2024-03-01T02:45:49.562625Z","shell.execute_reply":"2024-03-01T02:45:50.158324Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:45:52.031372Z","iopub.execute_input":"2024-03-01T02:45:52.031808Z","iopub.status.idle":"2024-03-01T02:45:52.040678Z","shell.execute_reply.started":"2024-03-01T02:45:52.031778Z","shell.execute_reply":"2024-03-01T02:45:52.039404Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(175621, 2)"},"metadata":{}}]},{"cell_type":"code","source":"data.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:45:56.754036Z","iopub.execute_input":"2024-03-01T02:45:56.754481Z","iopub.status.idle":"2024-03-01T02:45:56.766307Z","shell.execute_reply.started":"2024-03-01T02:45:56.754438Z","shell.execute_reply":"2024-03-01T02:45:56.764904Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  English words/sentences French words/sentences\n0                     Hi.                 Salut!\n1                    Run!                Cours !\n2                    Run!               Courez !\n3                    Who?                  Qui ?\n4                    Wow!             Ça alors !\n5                   Fire!               Au feu !\n6                   Help!             À l'aide !\n7                   Jump.                 Saute.\n8                   Stop!            Ça suffit !\n9                   Stop!                 Stop !","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English words/sentences</th>\n      <th>French words/sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Fire!</td>\n      <td>Au feu !</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Help!</td>\n      <td>À l'aide !</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Jump.</td>\n      <td>Saute.</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Stop!</td>\n      <td>Ça suffit !</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Stop!</td>\n      <td>Stop !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"os.cpu_count()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:45:59.439955Z","iopub.execute_input":"2024-03-01T02:45:59.440453Z","iopub.status.idle":"2024-03-01T02:45:59.449988Z","shell.execute_reply.started":"2024-03-01T02:45:59.440416Z","shell.execute_reply":"2024-03-01T02:45:59.448690Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"markdown","source":"We are shuffling the data to reduce the bias occurs in the data and to reduce the overfitting.","metadata":{}},{"cell_type":"code","source":"# Shuffle dataset\n\ndata = data.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:01.262905Z","iopub.execute_input":"2024-03-01T02:46:01.263282Z","iopub.status.idle":"2024-03-01T02:46:01.320478Z","shell.execute_reply.started":"2024-03-01T02:46:01.263254Z","shell.execute_reply":"2024-03-01T02:46:01.319243Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:03.241431Z","iopub.execute_input":"2024-03-01T02:46:03.242317Z","iopub.status.idle":"2024-03-01T02:46:03.254468Z","shell.execute_reply.started":"2024-03-01T02:46:03.242277Z","shell.execute_reply":"2024-03-01T02:46:03.253507Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                             English words/sentences  \\\n0                      At last, they ceased working.   \n1  The campers were hard up for water because the...   \n2                              That's what I'd want.   \n3         We don't really know anything about death.   \n4  The higher he rose in social rank, the more mo...   \n\n                              French words/sentences  \n0                 Ils cessèrent enfin de travailler.  \n1  Les campeurs étaient à court d'eau parce que l...  \n2                          C'est ce que je voudrais.  \n3           Nous ne savons vraiment rien de la mort.  \n4  Il est devenu de plus en plus humble alors qu'...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English words/sentences</th>\n      <th>French words/sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>At last, they ceased working.</td>\n      <td>Ils cessèrent enfin de travailler.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The campers were hard up for water because the...</td>\n      <td>Les campeurs étaient à court d'eau parce que l...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>That's what I'd want.</td>\n      <td>C'est ce que je voudrais.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We don't really know anything about death.</td>\n      <td>Nous ne savons vraiment rien de la mort.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The higher he rose in social rank, the more mo...</td>\n      <td>Il est devenu de plus en plus humble alors qu'...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"2. **CREATE DATASET**","metadata":{}},{"cell_type":"markdown","source":"We are splitting the dataset into 5% testing and 95% training part.","metadata":{}},{"cell_type":"code","source":"test_pct = 0.05  #testing percentage\nn_samples = len(data)\nn_test = int(n_samples * test_pct)\nn_train = n_samples - n_test\n\nprint(f\"Total samples: {n_samples}\")\nprint(f\"Test samples: {n_test}\")\nprint(f\"Train samples: {n_train}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:06.487404Z","iopub.execute_input":"2024-03-01T02:46:06.487835Z","iopub.status.idle":"2024-03-01T02:46:06.495402Z","shell.execute_reply.started":"2024-03-01T02:46:06.487802Z","shell.execute_reply":"2024-03-01T02:46:06.493752Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Total samples: 175621\nTest samples: 8781\nTrain samples: 166840\n","output_type":"stream"}]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:08.271461Z","iopub.execute_input":"2024-03-01T02:46:08.271902Z","iopub.status.idle":"2024-03-01T02:46:08.279673Z","shell.execute_reply.started":"2024-03-01T02:46:08.271869Z","shell.execute_reply":"2024-03-01T02:46:08.278428Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(175621, 2)"},"metadata":{}}]},{"cell_type":"markdown","source":"We are changing the names of columns for ease.","metadata":{}},{"cell_type":"code","source":"data.rename(columns={\"English words/sentences\":\"English\",\"French words/sentences\":\"French\"},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:10.054888Z","iopub.execute_input":"2024-03-01T02:46:10.055276Z","iopub.status.idle":"2024-03-01T02:46:10.062108Z","shell.execute_reply.started":"2024-03-01T02:46:10.055247Z","shell.execute_reply":"2024-03-01T02:46:10.060666Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Converting the data of both columns into numpy array.","metadata":{}},{"cell_type":"code","source":"english_text = data[\"English\"].to_numpy()\nfrench_text = data[\"French\"].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:13.006421Z","iopub.execute_input":"2024-03-01T02:46:13.006868Z","iopub.status.idle":"2024-03-01T02:46:13.013971Z","shell.execute_reply.started":"2024-03-01T02:46:13.006835Z","shell.execute_reply":"2024-03-01T02:46:13.012586Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:14.859677Z","iopub.execute_input":"2024-03-01T02:46:14.860063Z","iopub.status.idle":"2024-03-01T02:46:14.870071Z","shell.execute_reply.started":"2024-03-01T02:46:14.860035Z","shell.execute_reply":"2024-03-01T02:46:14.869178Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                             English  \\\n0                      At last, they ceased working.   \n1  The campers were hard up for water because the...   \n2                              That's what I'd want.   \n3         We don't really know anything about death.   \n4  The higher he rose in social rank, the more mo...   \n\n                                              French  \n0                 Ils cessèrent enfin de travailler.  \n1  Les campeurs étaient à court d'eau parce que l...  \n2                          C'est ce que je voudrais.  \n3           Nous ne savons vraiment rien de la mort.  \n4  Il est devenu de plus en plus humble alors qu'...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>At last, they ceased working.</td>\n      <td>Ils cessèrent enfin de travailler.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The campers were hard up for water because the...</td>\n      <td>Les campeurs étaient à court d'eau parce que l...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>That's what I'd want.</td>\n      <td>C'est ce que je voudrais.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We don't really know anything about death.</td>\n      <td>Nous ne savons vraiment rien de la mort.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The higher he rose in social rank, the more mo...</td>\n      <td>Il est devenu de plus en plus humble alors qu'...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We used zip function to take both the data i.e.,english_text & french_text together by using tensorflow dataset. After that, two variables created which shuffled the data taken from ds with declared buffer and batch size.","metadata":{}},{"cell_type":"code","source":"BUFFER_SIZE = 1000\nBATCH_SIZE = 64\n\nds = tf.data.Dataset.zip(\n    tf.data.Dataset.from_tensor_slices(english_text),\n    tf.data.Dataset.from_tensor_slices(french_text)\n)\n\ntest_raw = ds.take(n_test).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ntrain_raw = ds.skip(n_test).shuffle(BUFFER_SIZE).batch(BATCH_SIZE) # skip the n_test","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:17.551249Z","iopub.execute_input":"2024-03-01T02:46:17.551923Z","iopub.status.idle":"2024-03-01T02:46:17.730319Z","shell.execute_reply.started":"2024-03-01T02:46:17.551888Z","shell.execute_reply":"2024-03-01T02:46:17.729458Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Iterate over train_raw and prints the english and french texts in numpy array with batch of only 1.","metadata":{}},{"cell_type":"code","source":"for english_batch, french_batch in train_raw.take(1):\n    print(\"English\")\n    print(english_batch[0:5].numpy())\n    print(\"\\nFrench\")\n    print(french_batch[0:5].numpy())","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:20.615807Z","iopub.execute_input":"2024-03-01T02:46:20.616243Z","iopub.status.idle":"2024-03-01T02:46:20.703732Z","shell.execute_reply.started":"2024-03-01T02:46:20.616213Z","shell.execute_reply":"2024-03-01T02:46:20.702537Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"English\n[b'I look forward to seeing them this spring.' b'He removed his shirt.'\n b'You were right, too.' b'She is expecting a baby in June.'\n b'Do you listen to the radio at home every day?']\n\nFrench\n[b\"J'attends avec impatience de les voir ce printemps.\"\n b'Il a retir\\xc3\\xa9 sa chemise.' b'Vous aviez aussi raison.'\n b'Elle attend un b\\xc3\\xa9b\\xc3\\xa9 pour juin.'\n b'\\xc3\\x89coutes-tu tous les jours la radio \\xc3\\xa0 la maison\\xe2\\x80\\xaf?']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"3. **TEXT VECTORIZATION**","metadata":{}},{"cell_type":"markdown","source":"Models don't understand text, so we need to find a way to convert words into numbers.\n\nTextVectorization maps each word to an integer. In the process it constructs a vocabulary (dictionary), mapping each word to a unique integer.","metadata":{}},{"cell_type":"markdown","source":"The Pythonfunction, tf_lower_and_split_punct, processes text data before vectorization. ","metadata":{}},{"cell_type":"code","source":"# Preparing vectorizers\ndef tf_lower_and_split_punct(text):\n    \n    # French text contains special symbols. Unicode normalization:\n    text = tf_text.normalize_utf8(text, 'NFKD')\n    # Lowercase\n    text = tf.strings.lower(text)\n    # Keep space, a to z, and select punctuation.\n    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n    # Add spaces around punctuation.\n    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n    # Strip whitespace.\n    text = tf.strings.strip(text)\n    # start and end tokens\n    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:24.260346Z","iopub.execute_input":"2024-03-01T02:46:24.260802Z","iopub.status.idle":"2024-03-01T02:46:24.268352Z","shell.execute_reply.started":"2024-03-01T02:46:24.260768Z","shell.execute_reply":"2024-03-01T02:46:24.267024Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Preparing english vectorizers.","metadata":{}},{"cell_type":"code","source":"# maximum amount of words in the vocabulary\nmax_vocab_size = 50000 \n\nenglish_vectorizer = TextVectorization(\n    standardize=tf_lower_and_split_punct,\n    max_tokens=max_vocab_size, \n    ragged=True, # ragged=True allows variable length input sequences\n)\n\n# fit vectorization on training dataset english only\nenglish_vectorizer.adapt(train_raw.map(lambda english, french: english))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:27.535286Z","iopub.execute_input":"2024-03-01T02:46:27.535771Z","iopub.status.idle":"2024-03-01T02:46:32.088318Z","shell.execute_reply.started":"2024-03-01T02:46:27.535738Z","shell.execute_reply":"2024-03-01T02:46:32.087102Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Now, we take a glimpse of vectorized representation of words or tokens in english vectorizer.","metadata":{}},{"cell_type":"code","source":"# vectorize example sentence\nexample_sentence = \"Example sentence\"\nprint(f\"Input: {example_sentence}\")\nprint(f\"Vectorized: {english_vectorizer(example_sentence)}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:34.567335Z","iopub.execute_input":"2024-03-01T02:46:34.567788Z","iopub.status.idle":"2024-03-01T02:46:34.643106Z","shell.execute_reply.started":"2024-03-01T02:46:34.567753Z","shell.execute_reply":"2024-03-01T02:46:34.641965Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Input: Example sentence\nVectorized: [   2 1618 1056    3]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The reason there are 4 tokens in above output is because there is a \\ token at the start and an \\ token at the end.","metadata":{}},{"cell_type":"code","source":"# get vocabulary size\nvocab_size = english_vectorizer.vocabulary_size()\nprint(f\"English Vocabulary size: {vocab_size}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:37.134936Z","iopub.execute_input":"2024-03-01T02:46:37.135383Z","iopub.status.idle":"2024-03-01T02:46:37.142701Z","shell.execute_reply.started":"2024-03-01T02:46:37.135349Z","shell.execute_reply":"2024-03-01T02:46:37.141398Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"English Vocabulary size: 14175\n","output_type":"stream"}]},{"cell_type":"code","source":"# get first 10 words in the English vocabulary\nprint(english_vectorizer.get_vocabulary()[0:10])","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:39.127270Z","iopub.execute_input":"2024-03-01T02:46:39.128455Z","iopub.status.idle":"2024-03-01T02:46:39.184911Z","shell.execute_reply.started":"2024-03-01T02:46:39.128413Z","shell.execute_reply":"2024-03-01T02:46:39.183660Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"['', '[UNK]', '[START]', '[END]', '.', 'i', 'you', 'to', 'the', '?']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Special tokens:\n\n*  '' : Padding\n* [UNK] : Unknown token, for words which are not in our vocab.\n* [START] : Start token, precedes every sentence\n* [END] : End token, succeeds every sentence","metadata":{}},{"cell_type":"markdown","source":"Preparing French Vectorizers.","metadata":{}},{"cell_type":"code","source":"french_vectorizer = TextVectorization(\n    standardize=tf_lower_and_split_punct,\n    max_tokens=max_vocab_size, \n    ragged=True, # ragged=True allows variable length input sequences\n)\n\n# fit vectorization on training dataset french only\nfrench_vectorizer.adapt(train_raw.map(lambda english, french: french))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:42.566350Z","iopub.execute_input":"2024-03-01T02:46:42.566838Z","iopub.status.idle":"2024-03-01T02:46:47.083383Z","shell.execute_reply.started":"2024-03-01T02:46:42.566793Z","shell.execute_reply":"2024-03-01T02:46:47.082096Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# vectorize example sentence\nexample_sentence = \"Comment vas-tu?\"\nprint(f\"Input: {example_sentence}\")\nprint(f\"Vectorized: {english_vectorizer(example_sentence)}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:48.752397Z","iopub.execute_input":"2024-03-01T02:46:48.752899Z","iopub.status.idle":"2024-03-01T02:46:48.767803Z","shell.execute_reply.started":"2024-03-01T02:46:48.752857Z","shell.execute_reply":"2024-03-01T02:46:48.766548Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Input: Comment vas-tu?\nVectorized: [   2 2237    1    9    3]\n","output_type":"stream"}]},{"cell_type":"code","source":"# get vocabulary size\nvocab_size = french_vectorizer.vocabulary_size()\nprint(f\"French Vocabulary size: {vocab_size}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:51.071792Z","iopub.execute_input":"2024-03-01T02:46:51.072340Z","iopub.status.idle":"2024-03-01T02:46:51.080276Z","shell.execute_reply.started":"2024-03-01T02:46:51.072297Z","shell.execute_reply":"2024-03-01T02:46:51.078898Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"French Vocabulary size: 27477\n","output_type":"stream"}]},{"cell_type":"code","source":"# get first 10 words in the French vocabulary\nprint(french_vectorizer.get_vocabulary()[0:10])","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:53.647724Z","iopub.execute_input":"2024-03-01T02:46:53.648129Z","iopub.status.idle":"2024-03-01T02:46:53.747185Z","shell.execute_reply.started":"2024-03-01T02:46:53.648098Z","shell.execute_reply":"2024-03-01T02:46:53.746009Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"['', '[UNK]', '[START]', '[END]', '.', 'je', 'de', 'a', '?', 'pas']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now,let's take a sample example from dataset to test both the vectorizers we are created.\n\nHere,we are checking the mappings that both the vectorizers did from text to integers.","metadata":{}},{"cell_type":"code","source":"for english_b, french_b in train_raw.take(1):\n    english = english_b[0]\n    french = french_b[0]\n    print(\"\\n\\nEnglish (Text)\\n\")\n    print(english)\n    print(\"\\n\\nEnglish (Tokens)\\n\")\n    print(english_vectorizer(english))\n    print(\"\\n\\nFrench (Text)\\n\")\n    print(french)\n    print(\"\\n\\nFrench (Tokens)\\n\")\n    print(french_vectorizer(french))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:46:56.343488Z","iopub.execute_input":"2024-03-01T02:46:56.343926Z","iopub.status.idle":"2024-03-01T02:46:56.424763Z","shell.execute_reply.started":"2024-03-01T02:46:56.343894Z","shell.execute_reply":"2024-03-01T02:46:56.423430Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"\n\nEnglish (Text)\n\ntf.Tensor(b'I liked what you said at the meeting.', shape=(), dtype=string)\n\n\nEnglish (Tokens)\n\ntf.Tensor([  2   5 692  30   6 139  44   8 346   4   3], shape=(11,), dtype=int64)\n\n\nFrench (Text)\n\ntf.Tensor(b\"J'ai aim\\xc3\\xa9 ce que tu as dit pendant la r\\xc3\\xa9union.\", shape=(), dtype=string)\n\n\nFrench (Tokens)\n\ntf.Tensor([  2  26 240  20  10  21 115  64 252  11 392   4   3], shape=(13,), dtype=int64)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**CREATE NEW DATASETS WITH WORD INDICES**","metadata":{}},{"cell_type":"markdown","source":"Now, we create the new datasets with the new word mappings(indices).","metadata":{}},{"cell_type":"markdown","source":"    Convert english and french to word indices (tokens).\n    Extract french_in and french_out from summary.\n    The difference between french_in and french_out is that they are shifted by one step relative to eachother, so that at each location the label is the next token.","metadata":{}},{"cell_type":"code","source":"def process_text(english, french):\n    \n    english_tok = english_vectorizer(english)\n    french_tok = french_vectorizer(french)\n    french_tok_in = french_tok[:,:-1]\n    french_tok_out = french_tok[:, 1:] \n    return (english_tok, french_tok_in), french_tok_out\n\ntrain_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\ntest_ds = test_raw.map(process_text, tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:47:01.406968Z","iopub.execute_input":"2024-03-01T02:47:01.407395Z","iopub.status.idle":"2024-03-01T02:47:01.726287Z","shell.execute_reply.started":"2024-03-01T02:47:01.407361Z","shell.execute_reply":"2024-03-01T02:47:01.725040Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Below code iterates over English-French sentence pairs, printing out the first 10 tokens of each English sentence, French input sentence, and shifted French output sentence.","metadata":{}},{"cell_type":"code","source":"for (english_tok, french_in), french_out in train_ds.take(1):\n    print(\"\\nEnglish tokens:\")\n    print(english_tok[0, :10].numpy()) \n    print(\"\\nFrench_in tokens:\")\n    print(french_in[0, :10].numpy())\n    print(\"\\nFrench_out tokens (shifted):\")\n    print(french_out[0, :10].numpy())","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:47:04.718861Z","iopub.execute_input":"2024-03-01T02:47:04.719287Z","iopub.status.idle":"2024-03-01T02:47:04.844752Z","shell.execute_reply.started":"2024-03-01T02:47:04.719255Z","shell.execute_reply":"2024-03-01T02:47:04.843324Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\nEnglish tokens:\n[  2  31 670   6   4   3]\n\nFrench_in tokens:\n[  2  14  22 136 586   4]\n\nFrench_out tokens (shifted):\n[ 14  22 136 586   4   3]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As we can see above, the French_out tokens are equivalent to the French_in tokens except they are shifted forward by 1.\n\nThis automatically creates labels for us, as each token in French_in is matched to the following token in French_out.","metadata":{}},{"cell_type":"markdown","source":"4. **BUILDING UP THE ENCODER-DECODER MODEL**","metadata":{}},{"cell_type":"code","source":"UNITS = 256","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:47:19.415278Z","iopub.execute_input":"2024-03-01T02:47:19.415795Z","iopub.status.idle":"2024-03-01T02:47:19.421098Z","shell.execute_reply.started":"2024-03-01T02:47:19.415761Z","shell.execute_reply":"2024-03-01T02:47:19.419674Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"**Encoder**:-\n\nPurpose: Process the english tokens.\n\nInput: English tokens.\n\nOutput: English encodings.","metadata":{}},{"cell_type":"markdown","source":"Following steps to be done:-\n\n1.Convert English tokens to word embeddings.\n\n2.Feed embeddings through Bi-directional RNN.\n\n3.Return final English encodings.","metadata":{}},{"cell_type":"code","source":"class Encoder(tf.keras.layers.Layer):\n    def __init__(self, vectorizer, units):\n        super(Encoder, self).__init__()\n        self.vectorizer = vectorizer\n        self.vocab_size = vectorizer.vocabulary_size()\n        self.units = units\n        \n        # The embedding layer converts tokens into vectors\n        self.embedding = tf.keras.layers.Embedding(\n            input_dim=self.vocab_size,\n            output_dim=units,\n        )\n        \n        # The RNN layer processes those vectors sequentially\n        self.rnn = tf.keras.layers.Bidirectional(\n            merge_mode='sum', # sum forward and backward activation\n            layer=tf.keras.layers.GRU(\n                units,\n                return_sequences=True,\n                recurrent_initializer='glorot_uniform'\n            )\n        )\n    \n    def call(self, x):\n        # 1. The embedding layer looks up the embedding vector for each token.\n        x = self.embedding(x)\n        # 2. The GRU processes the sequence of embeddings.\n        x = self.rnn(x)\n        # 3. Return the new sequence of embeddings.\n        return x\n    \n    def encode_text(self, texts):\n        \"\"\"\n        Converts a list of english texts into encodings\n        \"\"\"\n        texts = tf.convert_to_tensor(texts)\n        if len(texts.shape) == 0:\n            texts = tf.convert_to_tensor(texts)[tf.newaxis]\n        tokens = self.vectorizer(texts).to_tensor()\n        encodings = self(tokens)\n        return encodings","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:47:22.616520Z","iopub.execute_input":"2024-03-01T02:47:22.617563Z","iopub.status.idle":"2024-03-01T02:47:22.632826Z","shell.execute_reply.started":"2024-03-01T02:47:22.617515Z","shell.execute_reply":"2024-03-01T02:47:22.631214Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"encoder = Encoder(english_vectorizer, UNITS)\n\n# pass example english tokens\nenglish_enc = encoder(english_tok)\n\nprint(f'english tokens, shape (batch, s): {english_tok.shape}')\nprint(f'english encodings, shape (batch, s, units): {english_enc.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:48:01.553304Z","iopub.execute_input":"2024-03-01T02:48:01.553776Z","iopub.status.idle":"2024-03-01T02:48:01.865665Z","shell.execute_reply.started":"2024-03-01T02:48:01.553741Z","shell.execute_reply":"2024-03-01T02:48:01.864336Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"english tokens, shape (batch, s): (64, None)\nenglish encodings, shape (batch, s, units): (64, None, 256)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The reason that the shapes contain None is because each sentence has a variable length.","metadata":{}},{"cell_type":"markdown","source":"**Cross-Attention**:-","metadata":{}},{"cell_type":"markdown","source":"Purpose: The attention layer lets the decoder access the information extracted by the encoder. It essentially computes contextually aware word embeddings.\n\nInputs: English encodings\n\nOutputs: Attention vectors (contextually aware English encodings)","metadata":{}},{"cell_type":"markdown","source":"Steps we are taken:-\n\n1.Compute Multi-head Attention.\n\n2.Add Skip Connection.\n\n3.Layer Normalization.\n\n4.Return Attention vectors.","metadata":{}},{"cell_type":"code","source":"class CrossAttention(tf.keras.layers.Layer):\n    def __init__(self, units, **kwargs):\n        super().__init__()\n        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n        self.layernorm = tf.keras.layers.LayerNormalization()\n        self.add = tf.keras.layers.Add()\n\n    def call(self, french_enc, english_enc):\n        # compute attention vectors\n        attn_output, attn_scores = self.mha(\n            query=french_enc, # query: french encodings\n            value=english_enc, # value: condition on english encodings\n            return_attention_scores=True)\n        \n        # skip connection to preserve input signals\n        x = self.add([french_enc, attn_output])\n        # layer normalization\n        x = self.layernorm(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:48:06.610655Z","iopub.execute_input":"2024-03-01T02:48:06.611128Z","iopub.status.idle":"2024-03-01T02:48:06.620854Z","shell.execute_reply.started":"2024-03-01T02:48:06.611091Z","shell.execute_reply":"2024-03-01T02:48:06.619697Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"attention_layer = CrossAttention(UNITS)\n\n# simulate French embeddings\nembed = tf.keras.layers.Embedding(french_vectorizer.vocabulary_size(),\n                                  output_dim=UNITS)\nfrench_embed = embed(french_in)\n\n# pass French embeddings and English encodings\nresult = attention_layer(french_embed, english_enc)\n\nprint(f'English encodings, shape (batch, s, units): {english_enc.shape}')\nprint(f'French embeddings, shape (batch, t, units): {french_embed.shape}')\nprint(f'Attention result, shape (batch, t, units): {result.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:48:16.480302Z","iopub.execute_input":"2024-03-01T02:48:16.480756Z","iopub.status.idle":"2024-03-01T02:48:16.747584Z","shell.execute_reply.started":"2024-03-01T02:48:16.480722Z","shell.execute_reply":"2024-03-01T02:48:16.746454Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"English encodings, shape (batch, s, units): (64, None, 256)\nFrench embeddings, shape (batch, t, units): (64, None, 256)\nAttention result, shape (batch, t, units): (64, None, 256)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Decoder**:-","metadata":{}},{"cell_type":"markdown","source":"Purpose: Predict the next token given an input sequence.\n\nInputs: English encodings, French input tokens.\n\nOutputs: Logit predictions for next tokens.\n\nSteps we are taken:-\n\n1.Convert French tokens to word embeddings.\n\n2.Feed word embeddings through Uni-directional RNN.\n\n3.Use RNN output as Query for Cross-Attention on English encodings.\n\n4.Generate logit predictions for next token.","metadata":{}},{"cell_type":"code","source":"class Decoder(tf.keras.layers.Layer):\n    @classmethod\n    def add_method(cls, fun):\n        \"\"\"\n        This will allows us to add additional methods to the class later.\n        \"\"\"\n        setattr(cls, fun.__name__, fun)\n        return fun\n    \n    def __init__(self, vectorizer, units):\n        super(Decoder, self).__init__()\n        self.vectorizer = vectorizer\n        self.vocab_size = vectorizer.vocabulary_size()\n        \n        self.word_to_id = tf.keras.layers.StringLookup(\n            vocabulary=vectorizer.get_vocabulary(),\n            mask_token=\"\", oov_token=\"[UNK]\"\n        )\n        \n        self.id_to_word = tf.keras.layers.StringLookup(\n            vocabulary=vectorizer.get_vocabulary(),\n            mask_token=\"\", oov_token=\"[UNK]\",\n            invert=True\n        )\n        \n        self.start_token = self.word_to_id(\"[START]\")\n        self.end_token = self.word_to_id(\"[END]\")\n\n        # 1. The embedding layer converts token indices to vectors\n        self.units = units\n        self.embedding = tf.keras.layers.Embedding(\n            self.vocab_size,\n            units,\n        )\n\n        # 2. The RNN keeps track of what's been generated so far\n        self.rnn = tf.keras.layers.GRU(\n            units,\n            return_sequences=True,\n            return_state=True,\n            recurrent_initializer=\"glorot_uniform\",\n        )\n        \n        # 3. The RNN output will be the query for the attention layer\n        self.attention = CrossAttention(units)\n        \n        # 4. This fully connected layer produces the logits for each output token\n        self.output_layer = tf.keras.layers.Dense(self.vocab_size)\n        \n    def call(\n            self, \n            english_enc, \n            french_in, \n            state=None, \n            return_state=False):\n        \n        # 1. Convert french tokens to embeddings\n        x = self.embedding(french_in)\n        \n        # 2. Process the french embeddings\n        x, state = self.rnn(x, initial_state=state)\n        \n        # 3. Use the RNN output as the query for the attention over the english encodings\n        # Essentially condition the french encodings on the english encodings\n        x = self.attention(x, english_enc)\n        \n        # 4. Generate logit predictions for the next token\n        logits = self.output_layer(x)\n        \n        if return_state:\n            return logits, state,\n        else:\n            return logits","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:48:24.507811Z","iopub.execute_input":"2024-03-01T02:48:24.508241Z","iopub.status.idle":"2024-03-01T02:48:24.525480Z","shell.execute_reply.started":"2024-03-01T02:48:24.508207Z","shell.execute_reply":"2024-03-01T02:48:24.523964Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"decoder = Decoder(french_vectorizer, UNITS)\n\n# use example English encodings and French input tokens\nlogits = decoder(english_enc, french_in)\n\nprint(f'English encodings shape (encoder output and decoder input): (batch, s, units) {english_enc.shape}')\nprint(f'French input tokens shape (decoder input): (batch, t) {french_in.shape}')\nprint(f'Logits shape (decoder output): (batch, french_vocabulary_size) {logits.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:48:47.112535Z","iopub.execute_input":"2024-03-01T02:48:47.113052Z","iopub.status.idle":"2024-03-01T02:48:48.775435Z","shell.execute_reply.started":"2024-03-01T02:48:47.113013Z","shell.execute_reply":"2024-03-01T02:48:48.774429Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"English encodings shape (encoder output and decoder input): (batch, s, units) (64, None, 256)\nFrench input tokens shape (decoder input): (batch, t) (64, None)\nLogits shape (decoder output): (batch, french_vocabulary_size) (64, None, 27477)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now, we are ready for training this network but for inference we are going to add a couple more methods.","metadata":{}},{"cell_type":"code","source":"@Decoder.add_method\ndef get_initial_state(self, english_encodings):\n    batch_size = tf.shape(english_encodings)[0]\n    # create tensor of n=batch_size start tokens [START]\n    start_tokens = tf.fill([batch_size, 1], self.start_token)\n    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n    embedded = self.embedding(start_tokens)\n    return start_tokens, done, self.rnn.get_initial_state(embedded)[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:48:51.904176Z","iopub.execute_input":"2024-03-01T02:48:51.904856Z","iopub.status.idle":"2024-03-01T02:48:51.911378Z","shell.execute_reply.started":"2024-03-01T02:48:51.904821Z","shell.execute_reply":"2024-03-01T02:48:51.910037Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"@Decoder.add_method\ndef tokens_to_text(self, tokens):\n    \"\"\"\n    Convert tokens (word indices) to text\n    \"\"\"\n    words = self.id_to_word(tokens)\n    result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n    result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n    result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:48:54.551343Z","iopub.execute_input":"2024-03-01T02:48:54.551751Z","iopub.status.idle":"2024-03-01T02:48:54.559105Z","shell.execute_reply.started":"2024-03-01T02:48:54.551720Z","shell.execute_reply":"2024-03-01T02:48:54.557766Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"@Decoder.add_method\ndef get_next_token(\n        self, \n        english_encodings, \n        next_token, \n        done, \n        state, \n        temperature=0.0):\n    \"\"\"\n    Note: Temperature is a hyperparameter that regulates the randomness or creativity of the AI's responses in language models.\n    \"\"\"\n    # running self() automatically runs the call() method\n    logits, state = self(\n        english_encodings,\n        next_token,\n        state=state,\n        return_state=True\n    )\n    \n    if temperature == 0.00:\n        next_token = tf.argmax(logits, axis=-1)\n    else:\n        logits = logits[:, -1, :]/temperature\n        next_token = tf.random.categorical(logits, num_samples=1)\n        \n    # if a sequence produces an end_token, set it \"done\"\n    done = done | (next_token == self.end_token)\n    # once a sequence is done it only produces 0-padding\n    next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n    \n    return next_token, done, state","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:48:57.679463Z","iopub.execute_input":"2024-03-01T02:48:57.679905Z","iopub.status.idle":"2024-03-01T02:48:57.689944Z","shell.execute_reply.started":"2024-03-01T02:48:57.679872Z","shell.execute_reply":"2024-03-01T02:48:57.688724Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"With these extra functions, we can write a generation loop.","metadata":{}},{"cell_type":"code","source":"next_token, done, state = decoder.get_initial_state(english_enc)\ntokens = []\n\nfor n in range(10):\n    # run one step\n    next_token, done, state = decoder.get_next_token(\n        english_enc, next_token, done, state, temperature=1.0\n    )\n    # add the token to the output\n    tokens.append(next_token)\n\n# stack all the tokens together\ntokens = tf.concat(tokens, axis=-1) # (batch, t)\n\n# Convert the tokens back to strings\nresult = decoder.tokens_to_text(tokens)\nresult","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:49:09.778481Z","iopub.execute_input":"2024-03-01T02:49:09.778884Z","iopub.status.idle":"2024-03-01T02:49:11.372090Z","shell.execute_reply.started":"2024-03-01T02:49:09.778856Z","shell.execute_reply":"2024-03-01T02:49:11.370718Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(64,), dtype=string, numpy=\narray([b'mimportune mes jattendis realisable regrettez mintimidez muffins oceanographe eastwood presidente',\n       b'symptomes tuba limpression canaux boistu frapperais damis prennentils branches eloignees',\n       b'debat impudent cuit leurrons lancien allongiez verticales doreilles jules economise',\n       b'animes precieuse maccusezvous gobe rattachee abaisser cuismoi bigamie laccompagner presque',\n       b'allumettes projeter er explosifs kg ajoutezy projection exprimait personnalite reconquerir',\n       b'demarrera necessiter perdirent aviezvous agression preferee donnera joignions forum bu',\n       b'probabilites impresario discutezvous comportiez diego amenee appliqua surmene otages devines',\n       b'finissent hypothecaire sortes vertus nelevez trente derangeait dinacheve representezvous heureuse',\n       b'malbouffe lempechait cents voyageaient precise datteindre suiveur parapet batir floutee',\n       b'evident concentra frequence ondes rejouie ok quattendre ecrites amicale police',\n       b'souligne limmortalite mangerons atteindre peau sacamain loucha consola votres satisfaite',\n       b'prompte predire romanciere mangeames commis pressiez mettras quelconques marrees minnesota',\n       b'attendez suivezles parcouru designer qu effondres moffrir preparation souscription contourne',\n       b'detestable nimagine nappellera cet chauffe rafraichi endommages croira usb langues',\n       b'nexagerons mortels plaisantant fringant residents levanouissement rabbin narretent noublia souple',\n       b'suivi deplore songe pli profonde dalcool repondu denuees jappelle couard',\n       b'relation compensation urbaines captive fichemoi geants tournetil externe prete arrivez',\n       b'reprendre towada claustrophobe precurseur lesprit ressasser manquons lourdement paupieres faisaistu',\n       b'mangeront captivite bles luxe routine dissertation spontane lexperience motdepasse dinnocence',\n       b'range embarrasses carapates aile mordus perdezvous moore connectez relations grimaca',\n       b'ponctualite assister tapproche trouvaistu rencontrerons vains jadmettrai sympathise comprendre hasards',\n       b'reclamation dhabiter connut brise fine suspendus lenleveront determine amniotique frequence',\n       b'fletrir vite minorites bocaux chaussettes prendstoi faconnes gaspillage cidessus travaillai',\n       b'appartiennentils techauffer keio touchent deriger heritiers detergent reconnaitraije cellophane reparerai',\n       b'chiba lapa voirie pu molle gardiennes retournetoi poursuivit remuer dumes',\n       b'luimeme bowl decouvris frelons expliquez elephants koalas augure metouffait passestu',\n       b'accidents ble lanalogie dis designent semblent brochures romps renouvelable cables',\n       b'feignis battre interne reposames afghanistan consacrezvous gazon cible duvre effrontees',\n       b'donnerontils recherchee nautoriserais sevanouit clin mangez financier dirigions temoignerai vaniteux',\n       b'contrefacons suspendit bjork disaient javale restetil faveurs illicite routiere dabruti',\n       b'elargir calins tinrent largeur soupira ressource paieraientils lavions indolore enfuis',\n       b'habitue enfer injustice decembre mordre irresponsable opportunites recopie asseyez renovation',\n       b'juvenile mug lavezvous verrouillera lorgna laid indigestes racine mitiges finissez',\n       b'avare invitation pensait jambes microeconomie niras produites fete scellez fixetil',\n       b'facebook commandements baryton directeur laissela porteur essaiesen potable amateur penchez',\n       b'croupie briser egalite tant deconvenue chargee sashimi fusils herisse hall',\n       b'tombe rit ronronne auspices priorite fuiterent lise bataille assoyonsnous foies',\n       b'cigarettes menfuirai partiras napprecies melville sang puait pompee deducation omettre',\n       b'yard lamantins alitees promesse mevites herite amities commande campe fusse',\n       b'claires japplaudis ignores alerte bel expedierons vers possedezvous valorise souligne',\n       b'secher suspect envoyee intervention achetent symphonie pourras preferais pourparlers quaimeriezvous',\n       b'mapprecient condamne excitante appreciations noie quabsurdites derangetelle cuisit boreale confessa',\n       b'ecriteau debloquer lenseignant approuve reverai effemine perdants cercueil paye fleuve',\n       b'externe achat menuisier effectues voyageai essayant cueillir rectangle discutezvous depecherai',\n       b'preparezvous lextremisme jembrasse hommage rival retardons atteignent consiste [UNK] directrices',\n       b'lembrouiller arrivent bissextiles egal mimes distingue cercles distante obeiras carriole',\n       b'empaquete fourbu affreusement miel effrayants conjoints jaccroche embarrasserait envoielemoi bondees',\n       b'tattrapera lourde yokohama couverts surfer daugmentation incarcere opposee dormis disparaisse',\n       b'jouait darrivee indolente fuste ambition dessine prestation consacrees revenant fervente',\n       b'participerastu ralentissement attendezmoi horaire discuteront portons coller manager fervents an',\n       b'avoue girafe penchant naidera worth externe heures memes etais collectionne',\n       b'louie gratuite linvitames entretenezvous brulees larriere diplomate cherchaistu parfum mattendrastu',\n       b'grippe suivez consternation sameliorera irm saine rejet refugies recherchons oral',\n       b'approfondir jouetelle mexcusai louer posela menseigna batteries commi mecque instantanees',\n       b'interesser charmant corrigiez auraitpu rappellelui deroula essaierait chantage ness tombant',\n       b'd pagaille continu lenjeu lavidite gymnase c aiguille grimpait exposes',\n       b'linondation consommateurs vanite begaye tasses retrouviez tenseignerai repeterais miette dabandonner',\n       b'tardivement sauveur integral demandatil tailler crierent preferes parla automatiquement lecteurs',\n       b'trempai grogne donnezmen intrigante hockey navigues deboucher sandwich lavertit vaton',\n       b'comedies weekend pretexte verrouilla romanciere compense sentiez sashimi saque annoncera',\n       b'metier plaignent lextorsion saddam lannuaire tenez hallucinations initiative lapins redoutable',\n       b'desireux nadmets resterons definiriezvous porterent cestil toquer skieur defendre tenus',\n       b'klaxons securisant noublia abandonna effectivement clan jadmets etape dabattage attribua',\n       b'fuste gercees cheques loppression actif discerner jouames equivoque limaginions celebrons'],\n      dtype=object)>"},"metadata":{}}]},{"cell_type":"markdown","source":"Now the model is untrained, so the outputs are uniformly random items from the vocabulary.","metadata":{}},{"cell_type":"markdown","source":"**Combining Encoder and Decoder into Translator**:-","metadata":{}},{"cell_type":"markdown","source":"Purpose: Translate English to French.\n\nInputs: English tokens, French input tokens.\n\nOutputs: French translation.\n\nSteps we are taken:-\n\n1.Feed English tokens through Encoder, generate English encodings.\n\n2.Feed English encodings and French input tokens to Decoder, generate prediction logits.","metadata":{}},{"cell_type":"code","source":"class Translator(tf.keras.Model):\n    @classmethod\n    def add_method(cls, fun):\n        setattr(cls, fun.__name__, fun)\n        return fun\n\n    def __init__(self, units, english_vectorizer, french_vectorizer):\n        super().__init__()\n        # build the encoder and decoder\n        encoder = Encoder(english_vectorizer, units)\n        decoder = Decoder(french_vectorizer, units)\n        \n        self.encoder = encoder\n        self.decoder = decoder\n        \n    def call(self, inputs):\n        # extract english tokens and french input tokens\n        english_tok, french_in = inputs\n        # convert english tokens to encodings\n        english_enc = self.encoder(english_tok)\n        # compute logits from english encodings and french input tokens\n        logits = self.decoder(english_enc, french_in)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:49:29.615765Z","iopub.execute_input":"2024-03-01T02:49:29.616196Z","iopub.status.idle":"2024-03-01T02:49:29.625779Z","shell.execute_reply.started":"2024-03-01T02:49:29.616162Z","shell.execute_reply":"2024-03-01T02:49:29.623903Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"model = Translator(UNITS, english_vectorizer, french_vectorizer)\n\n# pass English tokens and French input tokens\nlogits = model((english_tok, french_in))\n\nprint(f'English tokens shape (encoder input): (batch, s, units) {english_tok.shape}')\nprint(f'English encodings shape (encoder output and decoder input): (batch, s, units) {english_enc.shape}')\nprint(f'French tokens shape (decoder input): (batch, t) {french_in.shape}')\nprint(f'Logits shape (decoder output): (batch, french_vocabulary_size) {logits.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:49:34.400561Z","iopub.execute_input":"2024-03-01T02:49:34.401011Z","iopub.status.idle":"2024-03-01T02:49:36.351392Z","shell.execute_reply.started":"2024-03-01T02:49:34.400979Z","shell.execute_reply":"2024-03-01T02:49:36.349768Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"English tokens shape (encoder input): (batch, s, units) (64, None)\nEnglish encodings shape (encoder output and decoder input): (batch, s, units) (64, None, 256)\nFrench tokens shape (decoder input): (batch, t) (64, None)\nLogits shape (decoder output): (batch, french_vocabulary_size) (64, None, 27477)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"5. **MODEL TRAINING**","metadata":{}},{"cell_type":"markdown","source":"For training, we need to implement our own masked loss and accuracy functions:","metadata":{}},{"cell_type":"code","source":"def masked_loss(y_true, y_pred):\n    # Calculate the loss for each item in the batch.\n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n        from_logits=True, reduction='none')\n    loss = loss_fn(y_true, y_pred)\n\n    # Mask off the losses on padding.\n    mask = tf.cast(y_true != 0, loss.dtype)\n    loss *= mask\n\n    # Return the total.\n    return tf.reduce_sum(loss)/tf.reduce_sum(mask)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:49:38.160238Z","iopub.execute_input":"2024-03-01T02:49:38.161007Z","iopub.status.idle":"2024-03-01T02:49:38.168665Z","shell.execute_reply.started":"2024-03-01T02:49:38.160960Z","shell.execute_reply":"2024-03-01T02:49:38.167131Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def masked_acc(y_true, y_pred):\n    # Calculate the loss for each item in the batch.\n    y_pred = tf.argmax(y_pred, axis=-1)\n    y_pred = tf.cast(y_pred, y_true.dtype)\n\n    match = tf.cast(y_true == y_pred, tf.float32)\n    mask = tf.cast(y_true != 0, tf.float32)\n\n    return tf.reduce_sum(match)/tf.reduce_sum(mask)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:49:40.583734Z","iopub.execute_input":"2024-03-01T02:49:40.584834Z","iopub.status.idle":"2024-03-01T02:49:40.591134Z","shell.execute_reply.started":"2024-03-01T02:49:40.584793Z","shell.execute_reply":"2024-03-01T02:49:40.590064Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Finalize the configuration of the model for training","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=masked_loss, \n              metrics=[masked_acc, masked_loss])","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:49:43.079751Z","iopub.execute_input":"2024-03-01T02:49:43.080470Z","iopub.status.idle":"2024-03-01T02:49:43.288852Z","shell.execute_reply.started":"2024-03-01T02:49:43.080433Z","shell.execute_reply":"2024-03-01T02:49:43.287414Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"Calculating some expected values related to a vocab size","metadata":{}},{"cell_type":"code","source":"# Results in floating point number\nvocab_size = 1.0 * french_vectorizer.vocabulary_size()\n\n{\n    \"expected_loss\": tf.math.log(vocab_size).numpy(),\n    \"expected_acc\": 1/vocab_size\n}","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:49:44.904428Z","iopub.execute_input":"2024-03-01T02:49:44.904852Z","iopub.status.idle":"2024-03-01T02:49:44.914926Z","shell.execute_reply.started":"2024-03-01T02:49:44.904818Z","shell.execute_reply":"2024-03-01T02:49:44.913831Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"{'expected_loss': 10.221105, 'expected_acc': 3.639407504458274e-05}"},"metadata":{}}]},{"cell_type":"markdown","source":"Above values should roughly match the values returned by running a few steps of evaluation:","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_ds, steps=20,return_dict=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:49:47.632590Z","iopub.execute_input":"2024-03-01T02:49:47.633102Z","iopub.status.idle":"2024-03-01T02:50:07.104879Z","shell.execute_reply.started":"2024-03-01T02:49:47.633067Z","shell.execute_reply":"2024-03-01T02:50:07.103552Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"20/20 [==============================] - 19s 492ms/step - loss: 10.2204 - masked_acc: 0.0196 - masked_loss: 5618.1396\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"{'loss': 10.220355033874512,\n 'masked_acc': 0.019607946276664734,\n 'masked_loss': 5618.1396484375}"},"metadata":{}}]},{"cell_type":"code","source":"history = model.fit(\n    train_ds.repeat(), # .repeat() makes it an infinite dataset\n    validation_data=test_ds,\n    epochs=20,\n    steps_per_epoch = 100, # since we are using an infinite dataset, we need to specify the number of steps per epoch\n    validation_steps = 20,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(patience=3)\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T02:50:12.290764Z","iopub.execute_input":"2024-03-01T02:50:12.291191Z","iopub.status.idle":"2024-03-01T03:21:51.822816Z","shell.execute_reply.started":"2024-03-01T02:50:12.291147Z","shell.execute_reply":"2024-03-01T03:21:51.821587Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Epoch 1/20\n100/100 [==============================] - 111s 939ms/step - loss: 6.0275 - masked_acc: 44.4682 - masked_loss: 3300.2385 - val_loss: 5.0378 - val_masked_acc: 35.3105 - val_masked_loss: 2766.7749\nEpoch 2/20\n100/100 [==============================] - 97s 969ms/step - loss: 4.6633 - masked_acc: 27.6446 - masked_loss: 2566.3909 - val_loss: 4.3513 - val_masked_acc: 23.1940 - val_masked_loss: 2370.0786\nEpoch 3/20\n100/100 [==============================] - 93s 929ms/step - loss: 4.1261 - masked_acc: 22.1249 - masked_loss: 2263.8718 - val_loss: 3.8906 - val_masked_acc: 21.5360 - val_masked_loss: 2139.8132\nEpoch 4/20\n100/100 [==============================] - 93s 927ms/step - loss: 3.6407 - masked_acc: 20.2808 - masked_loss: 2019.8252 - val_loss: 3.4485 - val_masked_acc: 19.6353 - val_masked_loss: 1879.9965\nEpoch 5/20\n100/100 [==============================] - 93s 932ms/step - loss: 3.2758 - masked_acc: 19.1406 - masked_loss: 1814.7247 - val_loss: 3.0537 - val_masked_acc: 18.0984 - val_masked_loss: 1655.1898\nEpoch 6/20\n100/100 [==============================] - 92s 922ms/step - loss: 2.9153 - masked_acc: 18.3215 - masked_loss: 1604.5708 - val_loss: 2.7780 - val_masked_acc: 17.3151 - val_masked_loss: 1519.6814\nEpoch 7/20\n100/100 [==============================] - 96s 962ms/step - loss: 2.6837 - masked_acc: 17.5996 - masked_loss: 1474.2098 - val_loss: 2.5796 - val_masked_acc: 17.7442 - val_masked_loss: 1413.0667\nEpoch 8/20\n100/100 [==============================] - 92s 924ms/step - loss: 2.4861 - masked_acc: 17.4179 - masked_loss: 1362.8872 - val_loss: 2.3276 - val_masked_acc: 17.3761 - val_masked_loss: 1266.5171\nEpoch 9/20\n100/100 [==============================] - 92s 924ms/step - loss: 2.3539 - masked_acc: 17.0720 - masked_loss: 1293.8530 - val_loss: 2.2431 - val_masked_acc: 17.0305 - val_masked_loss: 1225.5731\nEpoch 10/20\n100/100 [==============================] - 91s 911ms/step - loss: 2.2330 - masked_acc: 17.0943 - masked_loss: 1227.2848 - val_loss: 2.1707 - val_masked_acc: 16.9355 - val_masked_loss: 1184.5082\nEpoch 11/20\n100/100 [==============================] - 92s 919ms/step - loss: 2.1091 - masked_acc: 16.9947 - masked_loss: 1161.9153 - val_loss: 2.0778 - val_masked_acc: 16.8224 - val_masked_loss: 1136.4050\nEpoch 12/20\n100/100 [==============================] - 92s 925ms/step - loss: 2.0269 - masked_acc: 16.8477 - masked_loss: 1118.1642 - val_loss: 1.9991 - val_masked_acc: 16.7893 - val_masked_loss: 1099.8214\nEpoch 13/20\n100/100 [==============================] - 91s 913ms/step - loss: 1.9794 - masked_acc: 16.7359 - masked_loss: 1086.6138 - val_loss: 1.9285 - val_masked_acc: 16.6538 - val_masked_loss: 1051.7330\nEpoch 14/20\n100/100 [==============================] - 92s 924ms/step - loss: 1.9050 - masked_acc: 16.7156 - masked_loss: 1047.1848 - val_loss: 1.8805 - val_masked_acc: 16.9032 - val_masked_loss: 1026.9675\nEpoch 15/20\n100/100 [==============================] - 92s 919ms/step - loss: 1.8099 - masked_acc: 16.7384 - masked_loss: 992.3269 - val_loss: 1.8672 - val_masked_acc: 16.5004 - val_masked_loss: 1032.7386\nEpoch 16/20\n100/100 [==============================] - 93s 927ms/step - loss: 1.8023 - masked_acc: 16.6418 - masked_loss: 984.6284 - val_loss: 1.7788 - val_masked_acc: 16.7158 - val_masked_loss: 973.3636\nEpoch 17/20\n100/100 [==============================] - 92s 923ms/step - loss: 1.7604 - masked_acc: 16.6138 - masked_loss: 967.6281 - val_loss: 1.7036 - val_masked_acc: 16.7555 - val_masked_loss: 934.9564\nEpoch 18/20\n100/100 [==============================] - 92s 925ms/step - loss: 1.7351 - masked_acc: 16.5481 - masked_loss: 957.8745 - val_loss: 1.7024 - val_masked_acc: 16.3711 - val_masked_loss: 929.7139\nEpoch 19/20\n100/100 [==============================] - 92s 915ms/step - loss: 1.6647 - masked_acc: 16.5206 - masked_loss: 915.3524 - val_loss: 1.6462 - val_masked_acc: 16.3020 - val_masked_loss: 896.6976\nEpoch 20/20\n100/100 [==============================] - 95s 951ms/step - loss: 1.6731 - masked_acc: 16.4672 - masked_loss: 918.1211 - val_loss: 1.6537 - val_masked_acc: 16.3779 - val_masked_loss: 901.6862\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**INFERENCE** (Make Predictions from model on unseen data)","metadata":{}},{"cell_type":"code","source":"@Translator.add_method\ndef translate(self,\n              texts, *,\n              max_length=50,\n              temperature=0.0):\n    # Process the input texts\n    context = self.encoder.encode_text(texts)\n    batch_size = tf.shape(texts)[0]\n\n    # Setup the loop inputs\n    tokens = []\n    next_token, done, state = self.decoder.get_initial_state(context)\n\n    for _ in range(max_length):\n        # Generate the next token\n        next_token, done, state = self.decoder.get_next_token(context, next_token, done,  state, temperature)\n\n        # Collect the generated tokens\n        tokens.append(next_token)\n\n        if tf.executing_eagerly() and tf.reduce_all(done):\n            break\n\n    # Stack the lists of tokens and attention weights.\n    tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n\n    result = self.decoder.tokens_to_text(tokens)\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-03-01T03:21:59.106708Z","iopub.execute_input":"2024-03-01T03:21:59.107117Z","iopub.status.idle":"2024-03-01T03:21:59.118739Z","shell.execute_reply.started":"2024-03-01T03:21:59.107086Z","shell.execute_reply":"2024-03-01T03:21:59.117463Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"result = model.translate([\"Hi!\"]) \nresult[0].numpy().decode()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T03:26:40.812445Z","iopub.execute_input":"2024-03-01T03:26:40.813252Z","iopub.status.idle":"2024-03-01T03:26:41.248035Z","shell.execute_reply.started":"2024-03-01T03:26:40.813212Z","shell.execute_reply":"2024-03-01T03:26:41.246710Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"'salut ! '"},"metadata":{}}]}]}